# ğŸ§  Cognite â€” AI Engineering Tutor

A full-stack AI-powered engineering tutor with real-time chat, personalized lessons, adaptive quizzes, and learning analytics. Built with React, FastAPI, and Groq's Llama 3.1.

**Live Demo:** [aiengineeringtutor.vercel.app](https://aiengineeringtutor.vercel.app)

---

## âœ¨ Features

### ğŸ’¬ AI Chat Tutor
- Real-time **streaming responses** via Server-Sent Events â€” tokens appear as they're generated, just like ChatGPT
- Powered by **Groq's Llama 3.1** (14,400 free requests/day)
- Persistent chat history stored in **Firestore** â€” sessions survive page refreshes and logins
- Multiple chat sessions with auto-generated titles based on conversation context
- Suggested follow-up topics after each conversation
- Delete sessions with a hover-reveal button in the sidebar

### ğŸ“š Learn (Dashboard)
- Choose from **12 engineering topics**: Thermodynamics, Circuit Analysis, Data Structures, Fluid Mechanics, Control Systems, Quantum Computing, Machine Learning, Signal Processing, Structural Analysis, Algorithms, Materials Science, Electromagnetics
- AI-generated lessons tailored to your selected difficulty level
- Each lesson includes a **4-option multiple choice quiz**
- Personalized topic suggestions based on your chat history
- Breadcrumb navigation with difficulty badge while viewing a lesson

### ğŸ“Š Performance Analytics
- **4 stat cards** showing: Messages Sent, Lessons Viewed, Quizzes Taken, Accuracy %
- **Topics Studied** section showing all topics you've explored
- **Bar chart** showing correct vs incorrect answers per topic (powered by Recharts)
- Adjustable difficulty: Beginner ğŸŒ± / Intermediate ğŸŒ¿ / Advanced ğŸŒ³
- Reset performance data at any time

### ğŸ” Authentication & Persistence
- Firebase Authentication (Email/Password + Google Sign-In)
- Per-user chat sessions stored in **Firestore** under `users/{uid}/sessions/{sessionId}`
- Sessions auto-save with 1-second debounce after each message
- Sessions load on login sorted by most recent

### ğŸ›¡ï¸ Backend Security
- **Firebase ID token verification** on every API endpoint
- **Rate limiting** via SlowAPI: 30 chat requests/min, 20 title requests/min per user
- **Prompt validation middleware** blocks injection patterns and oversized inputs (>8000 chars)
- API keys never exposed to the browser â€” all LLM calls go through the backend

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Vercel)                 â”‚
â”‚              React + Vite + Tailwind CSS             â”‚
â”‚                                                      â”‚
â”‚  ChatPage  â”‚  DashboardPage  â”‚  PerformancePage      â”‚
â”‚     â†“              â†“                  â†“              â”‚
â”‚         geminiService.js (API client)                â”‚
â”‚         firestoreService.js (Firestore)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTPS + Firebase Auth Token
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Backend (Render)                    â”‚
â”‚                    FastAPI                           â”‚
â”‚                                                      â”‚
â”‚  Middleware: Auth â†’ Rate Limit â†’ Prompt Validation   â”‚
â”‚                                                      â”‚
â”‚  /api/chat/message    â†’ Streaming SSE                â”‚
â”‚  /api/chat/title      â†’ Title + topic suggestions    â”‚
â”‚  /api/lessons/generate â†’ Lesson + quiz               â”‚
â”‚  /api/lessons/quiz/submit â†’ Record answer            â”‚
â”‚  /api/analytics/stats  â†’ User stats                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Groq API          â”‚
        â”‚  Llama 3.1-8b-instantâ”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| Frontend | React 18, Vite, Tailwind CSS |
| Backend | FastAPI, Python 3.11 |
| LLM | Groq (Llama 3.1-8b-instant) |
| Auth | Firebase Authentication |
| Database | Firebase Firestore |
| Charts | Recharts |
| Rate Limiting | SlowAPI |
| Frontend Deploy | Vercel |
| Backend Deploy | Render |

---

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+
- Python 3.11+
- Firebase project
- Groq API key (free at [console.groq.com](https://console.groq.com))

### 1. Clone the repo

```bash
git clone https://github.com/jaycodes2/AI-Engineering-Tutor.git
cd AI-Engineering-Tutor
```

### 2. Backend setup

```bash
cd backend
pip install -r requirements.txt
```

Create `backend/.env`:
```env
GROQ_API_KEY=your_groq_api_key
FIREBASE_PROJECT_ID=your_firebase_project_id
```

Place your Firebase service account JSON at `backend/serviceAccount.json`.

Start the backend:
```bash
uvicorn backend.main:app --reload
```

Backend runs at `http://localhost:8000`. API docs at `http://localhost:8000/docs`.

### 3. Frontend setup

```bash
cd frontend
npm install
```

Create `frontend/.env`:
```env
VITE_FIREBASE_API_KEY=your_key
VITE_FIREBASE_AUTH_DOMAIN=your_project.firebaseapp.com
VITE_FIREBASE_PROJECT_ID=your_project_id
VITE_FIREBASE_APP_ID=your_app_id
VITE_API_BASE_URL=http://localhost:8000
```

Start the frontend:
```bash
npm run dev
```

Frontend runs at `http://localhost:5173`.

---

## ğŸŒ Deployment

### Backend â†’ Render

1. Connect your GitHub repo to [render.com](https://render.com)
2. Set build command: `pip install -r backend/requirements.txt`
3. Set start command: `uvicorn backend.main:app --host 0.0.0.0 --port $PORT`
4. Add environment variables:

| Key | Value |
|-----|-------|
| `GROQ_API_KEY` | your Groq key |
| `FIREBASE_PROJECT_ID` | your project ID |
| `FIREBASE_SERVICE_ACCOUNT_JSON` | minified JSON string of serviceAccount.json |
| `ALLOWED_ORIGINS_STR` | `https://your-app.vercel.app` |

### Frontend â†’ Vercel

1. Import your repo at [vercel.com](https://vercel.com)
2. Set root directory to `frontend`
3. Add environment variables (same as local `.env` but with production backend URL)
4. After deploy, add your Vercel domain to Firebase Console â†’ Authentication â†’ Authorized Domains

---

## ğŸ“ Project Structure

```
AI-Engineering-Tutor/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                    # FastAPI app entry point
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py              # Settings (pydantic-settings)
â”‚   â”‚   â””â”€â”€ firebase_auth.py       # Token verification dependency
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ prompt_validator.py    # Injection + size checks
â”‚   â”‚   â”œâ”€â”€ rate_limiter.py        # SlowAPI rate limiting
â”‚   â”‚   â””â”€â”€ uid_extractor.py       # Attach UID to request state
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py             # Pydantic request/response models
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ chat.py                # Chat + streaming endpoints
â”‚   â”‚   â”œâ”€â”€ lessons.py             # Lesson + quiz endpoints
â”‚   â”‚   â””â”€â”€ analytics.py          # Analytics endpoints
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ llm_service.py         # Groq API orchestration
â”‚       â””â”€â”€ analytics_service.py   # In-memory analytics store
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.jsx                # Root component + state
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ ChatPage.jsx       # Chat UI with streaming
    â”‚   â”‚   â”œâ”€â”€ DashboardPage.jsx  # Learn page
    â”‚   â”‚   â”œâ”€â”€ PerformancePage.jsx# Stats + charts
    â”‚   â”‚   â”œâ”€â”€ TopicSelector.jsx  # Topic picker grid
    â”‚   â”‚   â”œâ”€â”€ LessonModule.jsx   # Lesson display
    â”‚   â”‚   â””â”€â”€ Quiz.jsx           # Quiz component
    â”‚   â””â”€â”€ services/
    â”‚       â”œâ”€â”€ geminiService.js   # Backend API client (SSE streaming)
    â”‚       â”œâ”€â”€ firestoreService.js# Firestore chat persistence
    â”‚       â””â”€â”€ auth.js            # Firebase auth helpers
    â””â”€â”€ public/
```

---

## ğŸ”‘ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/chat/message` | Stream chat response (SSE) |
| `POST` | `/api/chat/title` | Generate chat title + suggestions |
| `POST` | `/api/lessons/generate` | Generate lesson + quiz for topic |
| `POST` | `/api/lessons/quiz/submit` | Submit quiz answer + get feedback |
| `POST` | `/api/analytics/event` | Record a learning event |
| `GET` | `/api/analytics/stats` | Get user stats |
| `GET` | `/health` | Health check |

All endpoints (except `/health`) require a Firebase ID token in the `Authorization: Bearer <token>` header.

---

## ğŸ“ˆ Groq Free Tier Limits

| Model | Requests/min | Requests/day | Tokens/min |
|-------|-------------|-------------|-----------|
| llama-3.1-8b-instant | 30 | 14,400 | 131,072 |
| llama-3.3-70b-versatile | 30 | 14,400 | 6,000 |

Switch models by setting `GROQ_MODEL=llama-3.3-70b-versatile` in your `.env` for smarter responses.

---

## ğŸ”’ Security Notes

- Never commit `serviceAccount.json` or `.env` to git
- Both are in `.gitignore` by default
- For production, pass `FIREBASE_SERVICE_ACCOUNT_JSON` as a minified JSON string in your hosting platform's environment variables

---

## ğŸ“„ License

MIT Â© 2026 Jay (jaycodes2)
